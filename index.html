<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Anuva Banwasi</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      max-width: 900px;
      margin: 40px auto 80px;
      line-height: 1.6;
      color: #333;
      padding: 0 20px;
    }

    h1 {
      text-align: center;
      margin-bottom: 40px;
      font-weight: 500;
    }

    .top-section {
      display: flex;
      flex-wrap: wrap;
      gap: 40px;
      align-items: flex-start;
    }

    .profile-pic {
      width: 180px;
      height: auto;
      border-radius: 6px;
      object-fit: cover;
      display: block;
    }

    .bio {
      flex: 1;
      min-width: 250px;
    }

    .bio p:first-of-type {
      margin-top: 0;
    }

    a {
      color: #1a0dab;
      text-decoration: none;
    }
    a:hover { text-decoration: underline; }

    .section {
      margin-top: 60px;
    }

    /* Publications */
    .publication {
      display: flex;
      align-items: flex-start;
      gap: 20px;
      margin-bottom: 40px;
    }

    .publication img {
      width: 180px;
      height: auto;
      border-radius: 6px;
      object-fit: cover;
    }

    .pub-entry {
      flex: 1;
    }

    .pub-title {
      font-weight: 500;
      margin-bottom: 6px;
    }

    .pub-authors {
      font-style: italic;
      margin-bottom: 4px;
    }

    .pub-links a {
      margin-right: 10px;
    }

    /* Research Experience list */
    .exp-entry {
      margin-bottom: 30px;
    }

    .exp-title {
      font-weight: 500;
    }

    .exp-role {
      font-style: italic;
      margin-bottom: 6px;
    }
  </style>
</head>

<body>

  <h1>Anuva Banwasi</h1>

  <!-- ================= TOP SECTION ================ -->
  <div class="top-section">
    <img class="profile-pic" src="profile.jpg" alt="Profile Photo">

    <div class="bio">
      <p>
        I am a researcher in robotics and embodied AI, working on long-horizon memory,
        3D perception, and interaction-driven scene understanding for mobile manipulators.
        I currently work in the Interactive Perception & Robot Learning Lab at Stanford University,
        mentored by Professor Jeannette Bohg and Dr. Cherie Ho.
      </p>

      <p>
        Previously, I graduated cum laude from Columbia University with a B.S. in Computer Science, 
        where I worked on zero-shot task understanding and evaluation for long-horizon tasks
        under the guidance of Professor Shuran Song.
      </p>

      <p>Email: <a href="mailto:anuva.banwasi@gmail.com">anuva.banwasi@gmail.com</a></p>

      <p>
        <a href="Anuva_Banwasi_Resume.pdf">[CV]</a>
        <a href="https://scholar.google.com/citations?user=RW7glMsAAAAJ&hl=en">[Google Scholar]</a>
        <a href="https://github.com/anuvabanwasi">[GitHub]</a>
      </p>
    </div>
  </div>


  <!-- ================= RESEARCH EXPERIENCE ================ -->
  <div class="section">
    <h2>Research Experience</h2>

    <!-- 1. Stanford IPRL -->
    <div class="exp-entry">
      <div class="exp-title">Stanford University — Interactive Perception & Robot Learning Lab</div>
      <div class="exp-role">Robotics Researcher · March 2025 – present · Mentors: Prof. Jeannette Bohg, Dr. Cherie Ho</div>
      <p>
        Developing a persistent, object-centric memory system linking RGB-D perception with adaptive task
        planning for mobile manipulators. Built a real-time scene graph that synchronizes perception,
        action, and memory. Previously worked on building a grasp evaluation pipeline for dexterous multi-finger grasping 
        using enocded 3D Gaussian Splats as object representation, achieving a 95% grasp success rate across diverse objects.
      </p>
    </div>

    <!-- 2. Columbia Speech Lab -->
    <div class="exp-entry">
      <div class="exp-title">Columbia University — Speech Lab</div>
      <div class="exp-role">NLP Researcher · May 2023 – Dec 2023 · Mentor: Prof. Julia Hirschberg</div>
      <p>
        Built an emotion-aware conversational AI system combining ASR, prosodic features, and LLM
        reasoning to detect sudden emotion shifts from neutral or happy to sad or anger. Multimodal fusion of transcripts, 
        audio embeddings, and dialogue context. Trained on 150+ IEMOCAP videos (~10GB), improving accuracy from ~40% to 78%.
      </p>
    </div>

    <!-- 3. Columbia Robot Learning -->
    <div class="exp-entry">
      <div class="exp-title">Columbia University — Robot Learning</div>
      <div class="exp-role">Independent Researcher · Nov 2022 – Aug 2023 · Mentor: Prof. Shuran Song</div>
      <p>
        Led a team of 4 researchers to build zero-shot learning framework that assesses step-by-step task execution 
        for long-horizon tasks. Algorithm describes predicted step outcome with LLM, evaluates video data against language 
        outcome description with VLM, and assesses incremental progress with custom scoring metric. Achieved ~95% accuracy
        across diverse household and kitchen tasks. First-author publication at International Conference for Robotics and Computer Vision
        (ICRCV) 2023.
      </p>
    </div>

    <!-- 4. Forecasting -->
    <div class="exp-entry">
      <div class="exp-title">Columbia University — ML & Forecasting</div>
      <div class="exp-role">Student Researcher · Oct 2023 – July 2024 · Mentor: Prof. Michelle Levine</div>
      <p>
        Built vector autoregression models to forecast EV adoption using policy incentives and 
        charging infrastructure data. Produced a first-author publication at ITISE 2024.
      </p>
    </div>

    <!-- 5. CML -->
    <div class="exp-entry">
      <div class="exp-title">Columbia University — Creative Machines Lab</div>
      <div class="exp-role">Undergraduate Researcher · Sept 2022 – Dec 2022 · Mentor: Prof. Hod Lipson</div>
      <p>
        Designed a NeRF-inspired model that learns robot kinematics from single-view video by predicting 
        occupancy from 3D coordinates and joint angles. Used PyBullet-derived camera intrinsics to 
        reconstruct 3D geometry from 2D single-view data.
      </p>
    </div>
  </div>


  <!-- ================= PUBLICATIONS ================ -->
  <div class="section">
  <h2>Recent Publications</h2>

  <!-- 1 -->
  <div class="publication">
    <img src="pub1.jpg">
    <div class="pub-entry">
      <div class="pub-title">Self Evaluation Using Zero-shot Learning</div>
      <div class="pub-authors">Anuva Banwasi, Xinghua Sun, Rohith Ravindranath, March Vazquez</div>
      <div>
        <i>International Conference on Robotics and Computer Vision (ICRCV)</i>, Nanjing, 2023.  
        doi: <a href="https://doi.org/10.1109/ICRCV59470.2023.10329149">10.1109/ICRCV59470.2023.10329149</a>
      </div>
      <div class="pub-links">
        <a href="https://doi.org/10.1109/ICRCV59470.2023.10329149">[paper]</a>
      </div>
    </div>
  </div>

  <!-- 2 -->
  <div class="publication">
    <img src="pub2.jpg">
    <div class="pub-entry">
      <div class="pub-title">Promoting Electric Vehicle Growth through Infrastructure and Policy</div>
      <div class="pub-authors">Anuva Banwasi, Adele M Sinai, Brennan Xavier McManus</div>
      <div>
        <i>International Conference on Time Series and Forecasting (ITISE)</i>, 2024.  
        doi: <a href="https://doi.org/10.3390/engproc2024068060">10.3390/engproc2024068060</a>
      </div>
      <div class="pub-links">
        <a href="https://doi.org/10.3390/engproc2024068060">[paper]</a>
      </div>
    </div>
  </div>

  <!-- 3 -->
  <div class="publication">
    <img src="pub3.jpg">
    <div class="pub-entry">
      <div class="pub-title">A Comparative Analysis of Guardrail Frameworks for LLMs</div>
      <div class="pub-authors">Anuva Banwasi, Samuel Friedman, Michael Khanzadeh</div>
      <div>Under review at <i>ACL 2026</i>.</div>
      <div class="pub-links">
        <a href="https://github.com/llmguardrails/LLMGuardrailsPaper">[manuscript]</a>
      </div>
    </div>
  </div>

  <!-- 4 -->
  <div class="publication">
    <img src="pub4.jpg">
    <div class="pub-entry">
      <div class="pub-title">Hands Off, Splat On: Dexterous Grasp Evaluator with 3D Gaussian Encodings</div>
      <div class="pub-authors">Anuva Banwasi, Yi Du, Ashwin Mahendran</div>
      <div>In submission.</div>
      <div class="pub-links">
        <a href="https://github.com/Dude346/CS231A">[code]</a>
      </div>
    </div>
  </div>

</div>

</body>
</html>
